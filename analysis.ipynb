{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyses the total generation (in MWh), total generation revenue (in AUD) and the volume-weighted average price for various fuel types in the National Electricity Market (NEM).\n",
    "\n",
    "The input data includes:\n",
    "1. Spot prices for all regions of the NEM, with 5-minute resolution, covering the period from FY2020 to FY2024.\n",
    "    -- ##Production\\Report\\Electricity\\Generation\\Actual\\Region\\Metered\\Generation Stack FuelType ScheduleType (5min)\n",
    "2. Dispatched electricity by fuel type across all NEM regions, with 5-minute resolution, for the same FY2020 to FY2024 period.\n",
    "    -- ##Production\\Report\\Electricity\\Price\\Actual\\NEM\\Dispatch (5min)\\Dispatch Price all regions (5min)\n",
    "\n",
    "These analyses aim to provide insights into generation performance and pricing dynamics by fuel type in the NEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r'C:\\Users\\wwang2\\Documents\\GitHub\\NEM-generation\\data'\n",
    "output_path = r'C:\\Users\\wwang2\\Documents\\GitHub\\NEM-generation\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ToD function to add time-related columns\n",
    "def ToD(df):\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%d/%m/%Y %H:%M:%S')\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['CY'] = df['DateTime'].dt.year\n",
    "    df['Quarter'] = df['DateTime'].dt.quarter\n",
    "    df['FY'] = df['DateTime'].map(lambda d: d.year + 1 if d.month > 6 else d.year)\n",
    "    df['Hour'] = df['DateTime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dispatch price data\n",
    "price_df = pd.read_csv(path.join(input_path, 'Spot Price_2019_2024.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of state to the corresponding dispatch price column\n",
    "state_price_col = {\n",
    "    'NSW': 'NSW1 DISPATCH_PRICE',\n",
    "    'QLD': 'QLD1 DISPATCH_PRICE',\n",
    "    'VIC': 'VIC1 DISPATCH_PRICE',\n",
    "    'SA':  'SA1 DISPATCH_PRICE',\n",
    "    'TAS': 'TAS1 DISPATCH_PRICE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each generation file\n",
    "state_list = ['NSW', 'QLD', 'VIC', 'SA', 'TAS']\n",
    "generation_types = ['Schedule', 'Semi_Schedule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store aggregated results\n",
    "aggregated_results = []\n",
    "\n",
    "for state in state_list:\n",
    "    for gen_type in generation_types:\n",
    "        # Generate the file pattern for each state's generation files (Schedule and Semi_Schedule)\n",
    "        file_pattern = f'{state}1_{gen_type}_2019_2024_5_minutes.csv'\n",
    "        \n",
    "        # Load the generation data for the current state and generation type\n",
    "        try:\n",
    "            gen_df = pd.read_csv(path.join(input_path, file_pattern))\n",
    "            # print(\"found file: \", file_pattern)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f'File not found: {file_pattern}')\n",
    "        \n",
    "        # Add time-related columns using the ToD function\n",
    "        ToD(gen_df)\n",
    "\n",
    "        gen_df['DateTime'] = pd.to_datetime(gen_df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "        price_df['DateTime'] = pd.to_datetime(price_df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "        \n",
    "        # Merge the generation data with the dispatch price data\n",
    "        merged_df = pd.merge(gen_df, price_df[['DateTime', state_price_col[state]]], on='DateTime', how='inner')\n",
    "\n",
    "        # Calculate MWh dispatched by dividing MW by 12, while keeping DISPATCH_MW\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MW' in col:  # Identify generation columns\n",
    "                merged_df[col.replace('DISPATCH_MW', 'DISPATCH_MWh')] = merged_df[col] / 12\n",
    "        \n",
    "        # Calculate revenue: MWh dispatched * dispatch price for the state\n",
    "        dispatch_price_col = state_price_col[state]\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MWh' in col:  # Identify MWh columns\n",
    "                fuel_type = col.replace(' DISPATCH_MWh', '')  # Extract fuel type\n",
    "                merged_df[f'{fuel_type} REVENUE'] = merged_df[col] * merged_df[dispatch_price_col]\n",
    "\n",
    "        # Aggregate the data at the level of financial year, quarter, month, hour\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MWh' in col:  # Identify MWh columns\n",
    "                fuel_type = col.replace(' DISPATCH_MWh', '')  # Extract fuel type\n",
    "                # Group by time dimensions and calculate total MWh, total revenue, and VWAP\n",
    "                agg_df = merged_df.groupby(['FY']).agg(\n",
    "                    Total_MWh_Dispatched=(col, 'sum'),\n",
    "                    Total_Revenue=(f'{fuel_type} REVENUE', 'sum')\n",
    "                ).reset_index()\n",
    "                \n",
    "                # Calculate VWAP (Total Revenue / Total MWh Dispatched)\n",
    "                agg_df['VWAP'] = agg_df['Total_Revenue'] / agg_df['Total_MWh_Dispatched']\n",
    "                agg_df['State'] = state\n",
    "                agg_df['Fuel_Type'] = fuel_type\n",
    "                \n",
    "                # Store the aggregated data in the results list\n",
    "                aggregated_results.append(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FY  Total_MWh_Dispatched  Total_Revenue        VWAP State Fuel_Type  \\\n",
      "0  2020              0.000000   0.000000e+00         NaN   NSW   Battery   \n",
      "1  2021              0.000000   0.000000e+00         NaN   NSW   Battery   \n",
      "2  2022          13780.540833   5.091473e+06  369.468286   NSW   Battery   \n",
      "3  2023          22553.717500   6.361942e+06  282.079513   NSW   Battery   \n",
      "4  2024         102064.612500   2.842369e+07  278.487248   NSW   Battery   \n",
      "\n",
      "   % of total MWh dispatched  % of total revenue  \n",
      "0                   0.000000            0.000000  \n",
      "1                   0.000000            0.000000  \n",
      "2                   0.007433            0.019770  \n",
      "3                   0.012205            0.024232  \n",
      "4                   0.055171            0.159216  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate all aggregated results into a single DataFrame\n",
    "final_agg_df = pd.concat(aggregated_results)\n",
    "\n",
    "# Calculate the sum of 'Total_MWh_Dispatched' and 'Total_Revenue' for each financial year\n",
    "sum_mwh_fy = final_agg_df.groupby('FY')['Total_MWh_Dispatched'].transform('sum')\n",
    "sum_revenue_fy = final_agg_df.groupby('FY')['Total_Revenue'].transform('sum')\n",
    "\n",
    "# Calculate the new columns\n",
    "final_agg_df['% of total MWh dispatched'] = final_agg_df['Total_MWh_Dispatched'] / sum_mwh_fy * 100\n",
    "final_agg_df['% of total revenue'] = final_agg_df['Total_Revenue'] / sum_revenue_fy * 100\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(final_agg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated result to a new CSV file\n",
    "final_agg_df.to_csv(path.join(output_path, 'NEM_generation.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store aggregated results\n",
    "aggregated_results_ToD = []\n",
    "\n",
    "for state in state_list:\n",
    "    for gen_type in generation_types:\n",
    "        # Generate the file pattern for each state's generation files (Schedule and Semi_Schedule)\n",
    "        file_pattern = f'{state}1_{gen_type}_2019_2024_5_minutes.csv'\n",
    "        \n",
    "        # Load the generation data for the current state and generation type\n",
    "        try:\n",
    "            gen_df = pd.read_csv(path.join(input_path, file_pattern))\n",
    "            # print(\"found file: \", file_pattern)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f'File not found: {file_pattern}')\n",
    "        \n",
    "        # Add time-related columns using the ToD function\n",
    "        ToD(gen_df)\n",
    "\n",
    "        gen_df['DateTime'] = pd.to_datetime(gen_df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "        price_df['DateTime'] = pd.to_datetime(price_df['DateTime'], format='%d/%m/%Y %H:%M')\n",
    "        \n",
    "        # Merge the generation data with the dispatch price data\n",
    "        merged_df = pd.merge(gen_df, price_df[['DateTime', state_price_col[state]]], on='DateTime', how='inner')\n",
    "\n",
    "        # Calculate MWh dispatched by dividing MW by 12, while keeping DISPATCH_MW\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MW' in col:  # Identify generation columns\n",
    "                merged_df[col.replace('DISPATCH_MW', 'DISPATCH_MWh')] = merged_df[col] / 12\n",
    "        \n",
    "        # Calculate revenue: MWh dispatched * dispatch price for the state\n",
    "        dispatch_price_col = state_price_col[state]\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MWh' in col:  # Identify MWh columns\n",
    "                fuel_type = col.replace(' DISPATCH_MWh', '')  # Extract fuel type\n",
    "                merged_df[f'{fuel_type} REVENUE'] = merged_df[col] * merged_df[dispatch_price_col]\n",
    "\n",
    "        # Aggregate the data at the level of financial year, quarter, month, hour\n",
    "        for col in merged_df.columns:\n",
    "            if 'DISPATCH_MWh' in col:  # Identify MWh columns\n",
    "                fuel_type = col.replace(' DISPATCH_MWh', '')  # Extract fuel type\n",
    "                # Group by time dimensions and calculate total MWh, total revenue, and VWAP\n",
    "                agg_df = merged_df.groupby(['FY', 'Hour']).agg(\n",
    "                    Total_MWh_Dispatched=(col, 'sum'),\n",
    "                    Total_Revenue=(f'{fuel_type} REVENUE', 'sum')\n",
    "                ).reset_index()\n",
    "                \n",
    "                # Calculate VWAP (Total Revenue / Total MWh Dispatched)\n",
    "                agg_df['VWAP'] = agg_df['Total_Revenue'] / agg_df['Total_MWh_Dispatched']\n",
    "                agg_df['State'] = state\n",
    "                agg_df['Fuel_Type'] = fuel_type\n",
    "                \n",
    "                # Store the aggregated data in the results list\n",
    "                aggregated_results_ToD.append(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FY  Hour  Total_MWh_Dispatched  Total_Revenue  VWAP State Fuel_Type  \\\n",
      "0  2020     0                   0.0            0.0   NaN   NSW   Battery   \n",
      "1  2020     1                   0.0            0.0   NaN   NSW   Battery   \n",
      "2  2020     2                   0.0            0.0   NaN   NSW   Battery   \n",
      "3  2020     3                   0.0            0.0   NaN   NSW   Battery   \n",
      "4  2020     4                   0.0            0.0   NaN   NSW   Battery   \n",
      "\n",
      "   % of total MWh dispatched  % of total revenue  \n",
      "0                        0.0                 0.0  \n",
      "1                        0.0                 0.0  \n",
      "2                        0.0                 0.0  \n",
      "3                        0.0                 0.0  \n",
      "4                        0.0                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate all aggregated results into a single DataFrame\n",
    "final_agg_df_ToD = pd.concat(aggregated_results_ToD)\n",
    "\n",
    "# Calculate the sum of 'Total_MWh_Dispatched' and 'Total_Revenue' for each financial year and hour\n",
    "sum_mwh_fy_ToD = final_agg_df_ToD.groupby(['FY', 'Hour'])['Total_MWh_Dispatched'].transform('sum')\n",
    "sum_revenue_fy_ToD = final_agg_df_ToD.groupby(['FY', 'Hour'])['Total_Revenue'].transform('sum')\n",
    "\n",
    "# Calculate the new columns\n",
    "final_agg_df_ToD['% of total MWh dispatched'] = final_agg_df_ToD['Total_MWh_Dispatched'] / sum_mwh_fy_ToD * 100\n",
    "final_agg_df_ToD['% of total revenue'] = final_agg_df_ToD['Total_Revenue'] / sum_revenue_fy_ToD * 100\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(final_agg_df_ToD.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aggregated result to a new CSV file\n",
    "final_agg_df_ToD.to_csv(path.join(output_path, 'NEM_generation_ToD.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
